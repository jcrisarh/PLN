{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZd5yLnnHOK0"
   },
   "source": [
    "# Procesamiento de lenguaje natural\n",
    "## Desafío 2\n",
    "### Custom embedddings con Gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
    "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
    "- Graficarlos.\n",
    "- Obtener conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener los datos se utiliza un e-book libre obtenido de Project Gutemberg: https://www.gutenberg.org/ebooks/58650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Introduction to the study of the history of language\n",
    "\n",
    "Author: Herbert A. Strong\n",
    "        Willem Sijbrand Logeman\n",
    "        Benjamin Ide Wheeler\n",
    "\n",
    "Release date: January 8, 2019\n",
    "\n",
    "Language: English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "lFToQs5FK5uZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Introduction to the study of the history of language\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are l\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.path.join(\"docs\", \"Introduction_to_the_study_of_the_history_of_language.txt\")\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "print(text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que el libro tiene introducciones que son iguales en todos los e-books provenientes del proyecto Gutemberg, se elimina todo esto, tanto al principio como al final. De igual forma se tomo en cuenta para el análisis solamente el contenido del libro obviando el índice, prólogo y los títulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual forma, se encontró esta nota. por lo tanto, se eliminaron las delimitaciones a estas palabras que para este efecto podrian causar ruido.\n",
    "\n",
    "[Transcriber’s Note:\n",
    "\n",
    "Text delimited by underscores is italic.\n",
    "\n",
    "Text delimited by equal signs is bold.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_previous_text(text, intro_marker):\n",
    "    intro_index = text.find(intro_marker)\n",
    "    if intro_index !=-1:\n",
    "        return text[intro_index + len(intro_marker):].strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_underscores(text):\n",
    "    # remove italic delimitation\n",
    "    pattern = r'_([^_]+)_'\n",
    "    cleaned_text = re.sub(pattern, r'\\1', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_equal_signs(text):\n",
    "    # remove bold delimitation\n",
    "    pattern = r'=([^=]+)='\n",
    "    cleaned_text = re.sub(pattern, r'\\1', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_below(text, end_marker):\n",
    "    end_marker_pos = text.find(end_marker)\n",
    "    if end_marker_pos != -1:\n",
    "        return text[:end_marker_pos]\n",
    "    return text\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_chapter_text(text):\n",
    "    lines = text.split('\\n')\n",
    "    clean_lines = [line for line in lines if not re.match(r'^CHAPTER [IVXLCDM]+\\.$', line.strip())]\n",
    "    clean_text = '\\n'.join(clean_lines)\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_titles(text, titles):\n",
    "    lines = text.split('\\n')\n",
    "    clean_lines = [line for line in lines if not any(title in line for title in titles)]\n",
    "    clean_text = '\\n'.join(clean_lines)\n",
    "    return clean_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_lines(text):\n",
    "    lines = text.split('\\n')\n",
    "    clean_lines = [line for line in lines if line.strip()]\n",
    "    clean_text = '\\n'.join(clean_lines)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text saved to: docs/cleaned_text.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "intro_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK INTRODUCTION TO THE STUDY OF THE HISTORY OF LANGUAGE ***\"\n",
    "end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK INTRODUCTION TO THE STUDY OF THE HISTORY OF LANGUAGE ***\"\n",
    "index_marker = \"INDEX\"\n",
    "previous_chap_marker = \"” 176, line 7, for ‘ðoances’ read ‘ðances.’\"\n",
    "titles = [\n",
    "    \"ON THE DEVELOPMENT OF LANGUAGE\", \"ON THE DIFFERENTIATION OF LANGUAGE\", \"ON SOUND-CHANGE\", \"CHANGE IN WORD-SIGNIFICATION\", \n",
    "    \"ANALOGY\", \"THE FUNDAMENTAL FACTS OF SYNTAX\", \"CHANGE OF MEANING IN SYNTAX\", \"CONTAMINATION\", \"ORIGINAL CREATION\", \n",
    "    \"ON ISOLATION AND THE REACTION AGAINST IT\", \"THE FORMATION OF NEW GROUPS\", \"ON THE INFLUENCE OF CHANGE IN FUNCTION ON ANALOGICAL FORMATION\",\n",
    "    \"DISPLACEMENT IN ETYMOLOGICAL GROUPING\", \"ON THE DIFFERENTIATION OF MEANING\", \"CATEGORIES: PSYCHOLOGICAL AND GRAMMATICAL\", \"GENDER\", \"NUMBER\",\n",
    "    \"TENSE\", \"VOICE\", \"DISPLACEMENT OF THE SYNTACTICAL DISTRIBUTION\", \"ON CONCORD\", \"ECONOMY OF EXPRESSION\", \"RISE OF WORD-FORMATION AND INFLECTION\",\n",
    "    \"THE DIVISION OF THE PARTS OF SPEECH\", \"LANGUAGE AND WRITING\", \"ON MIXTURE IN LANGUAGE\", \"THE STANDARD LANGUAGE\" \n",
    "]\n",
    "\n",
    "cleaned_text = remove_previous_text(text, intro_marker)\n",
    "cleaned_text = remove_underscores(cleaned_text)\n",
    "cleaned_text = remove_equal_signs(cleaned_text)\n",
    "cleaned_text = remove_text_below(cleaned_text, end_marker)\n",
    "cleaned_text = remove_text_below(cleaned_text, index_marker)\n",
    "cleaned_text = remove_previous_text(cleaned_text, previous_chap_marker)\n",
    "cleaned_text = remove_chapter_text(cleaned_text)\n",
    "cleaned_text = remove_titles(cleaned_text, titles)\n",
    "cleaned_text = remove_empty_lines(cleaned_text)\n",
    "\n",
    "output_file_path = os.path.join(\"docs\", \"cleaned_text.txt\") \n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(cleaned_text)\n",
    "\n",
    "print(\"Cleaned text saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is the province of the Science of Language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>possible, the processes of the development of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to its latest stage. The observations made on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naturally be registered in different historica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definite languages; these grammars would follo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  It is the province of the Science of Language ...\n",
       "1  possible, the processes of the development of ...\n",
       "2  to its latest stage. The observations made on ...\n",
       "3  naturally be registered in different historica...\n",
       "4  definite languages; these grammars would follo..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(output_file_path, sep='/n', header=None, engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "LEpKubK9XzXN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos: 10588\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de documentos:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de words distintas en el corpus: 5084\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab94qaFlrA1G"
   },
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "rIsmMWmjrDHd"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "sentence_tokens = []\n",
    "for _, row in df[:None].iterrows():\n",
    "    sentence_tokens.append(text_to_word_sequence(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "CHepi_DGrbhq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'province',\n",
       "  'of',\n",
       "  'the',\n",
       "  'science',\n",
       "  'of',\n",
       "  'language',\n",
       "  'to',\n",
       "  'explain',\n",
       "  'as',\n",
       "  'far',\n",
       "  'as'],\n",
       " ['possible',\n",
       "  'the',\n",
       "  'processes',\n",
       "  'of',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'language',\n",
       "  'from',\n",
       "  'its',\n",
       "  'earliest']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaXV6nlHr5Aa"
   },
   "source": [
    "### Creación de los vectores (word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "OSb0v7h8r7hK"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "i0wnDdv9sJ47"
   },
   "outputs": [],
   "source": [
    "#modelo skipgram\n",
    "w2v_model = Word2Vec(min_count=5,    \n",
    "                     window=2,       \n",
    "                     vector_size=300,       \n",
    "                     negative=20,    \n",
    "                     workers=1,      \n",
    "                     sg=1)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "5lTt8wErsf17"
   },
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "TNc9qt4os5AT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de docs en el corpus: 10588\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "idw9cHF3tSMl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de words distintas en el corpus: 2209\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC9mZ8DPk-UC"
   },
   "source": [
    "### 3 - Entrenar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "QSp-x0PAsq56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 898804.25\n",
      "Loss after epoch 1: 633934.125\n",
      "Loss after epoch 2: 604372.125\n",
      "Loss after epoch 3: 528593.25\n",
      "Loss after epoch 4: 523853.0\n",
      "Loss after epoch 5: 521980.0\n",
      "Loss after epoch 6: 513216.75\n",
      "Loss after epoch 7: 482796.5\n",
      "Loss after epoch 8: 480711.0\n",
      "Loss after epoch 9: 474506.5\n",
      "Loss after epoch 10: 471428.5\n",
      "Loss after epoch 11: 468894.0\n",
      "Loss after epoch 12: 463245.0\n",
      "Loss after epoch 13: 461778.5\n",
      "Loss after epoch 14: 459479.5\n",
      "Loss after epoch 15: 455387.0\n",
      "Loss after epoch 16: 438607.0\n",
      "Loss after epoch 17: 438475.0\n",
      "Loss after epoch 18: 436146.0\n",
      "Loss after epoch 19: 434495.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1442155, 2384600)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentence_tokens,\n",
    "                 total_examples=w2v_model.corpus_count,\n",
    "                 epochs=20,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddT9NVuNlCAe"
   },
   "source": [
    "### Probar palabras de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"language\", \"linguistic\", \"phenomena\", \"dialect\", \"imperfect\", \"word\", \"sound\", \"ideas\", \"mind\", \"syntax\", \"similar\", \"meaning\", \"teutonic\", \"vowels\", \"influence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words for 'language':\n",
      "- dialect: 0.640992283821106\n",
      "- orthography: 0.6233234405517578\n",
      "- alphabet: 0.6084741950035095\n",
      "- standard: 0.6042174100875854\n",
      "- type: 0.5730559229850769\n",
      "- pre: 0.5708451271057129\n",
      "- harmony: 0.5628711581230164\n",
      "- usage: 0.5550401210784912\n",
      "- adoption: 0.5549219846725464\n",
      "- idiom: 0.5501529574394226\n",
      "\n",
      "Most similar words for 'linguistic':\n",
      "- community: 0.7204412221908569\n",
      "- human: 0.7185691595077515\n",
      "- speaker’s: 0.7130988240242004\n",
      "- proportion: 0.6935109496116638\n",
      "- etymological: 0.6874521970748901\n",
      "- factors: 0.6842604279518127\n",
      "- area: 0.6764870285987854\n",
      "- affects: 0.6742784380912781\n",
      "- system: 0.673038125038147\n",
      "- wider: 0.6715328693389893\n",
      "\n",
      "Most similar words for 'phenomena':\n",
      "- society: 0.876911461353302\n",
      "- levelling: 0.8664689660072327\n",
      "- code: 0.8662737011909485\n",
      "- interest: 0.8651589751243591\n",
      "- pitch: 0.8484036922454834\n",
      "- quantity: 0.8406350016593933\n",
      "- roots: 0.8397217392921448\n",
      "- phonetics: 0.8393345475196838\n",
      "- tendencies: 0.8360954523086548\n",
      "- plant: 0.8360311388969421\n",
      "\n",
      "Most similar words for 'dialect':\n",
      "- animal: 0.7171584367752075\n",
      "- code: 0.7115135192871094\n",
      "- basis: 0.7030459642410278\n",
      "- tongues: 0.6904563903808594\n",
      "- district: 0.6800640225410461\n",
      "- fanciful: 0.6760000586509705\n",
      "- alteration: 0.6737668514251709\n",
      "- steps: 0.6727554798126221\n",
      "- peculiarity: 0.6708389520645142\n",
      "- government: 0.6664711833000183\n",
      "\n",
      "Most similar words for 'imperfect':\n",
      "- mood: 0.7441497445106506\n",
      "- evil: 0.7423840761184692\n",
      "- prepositional: 0.7348188161849976\n",
      "- possibility: 0.7340096831321716\n",
      "- discussion: 0.7323221564292908\n",
      "- whenever: 0.7249739766120911\n",
      "- during: 0.723383903503418\n",
      "- tense: 0.7175545692443848\n",
      "- quoted: 0.7171791195869446\n",
      "- interrogation: 0.7165260910987854\n",
      "\n",
      "Most similar words for 'word':\n",
      "- particle: 0.6096765398979187\n",
      "- shade: 0.5834656357765198\n",
      "- pair: 0.5783228278160095\n",
      "- refers: 0.5721213221549988\n",
      "- continuous: 0.5662140250205994\n",
      "- specialisation: 0.564280092716217\n",
      "- idiom: 0.5640266537666321\n",
      "- symbol: 0.5616916418075562\n",
      "- conception: 0.557308554649353\n",
      "- translation: 0.5567609667778015\n",
      "\n",
      "Most similar words for 'sound':\n",
      "- verner’s: 0.6677066087722778\n",
      "- law: 0.6428923606872559\n",
      "- code: 0.5819801092147827\n",
      "- direction: 0.5740722417831421\n",
      "- movement: 0.5721998810768127\n",
      "- symbol: 0.562857449054718\n",
      "- flection: 0.5579730272293091\n",
      "- causes: 0.5424095988273621\n",
      "- pitch: 0.5406325459480286\n",
      "- mental: 0.5379930734634399\n",
      "\n",
      "Most similar words for 'ideas':\n",
      "- associate: 0.7521036863327026\n",
      "- ordination: 0.7447642683982849\n",
      "- senses: 0.7405198812484741\n",
      "- simultaneously: 0.7380222082138062\n",
      "- groupings: 0.7334539294242859\n",
      "- objects: 0.7306638956069946\n",
      "- human: 0.7237594723701477\n",
      "- relations: 0.7235439419746399\n",
      "- steps: 0.7225772738456726\n",
      "- psychical: 0.720735490322113\n",
      "\n",
      "Most similar words for 'mind':\n",
      "- minds: 0.751380205154419\n",
      "- associate: 0.7272522449493408\n",
      "- speaker’s: 0.7218478918075562\n",
      "- consciousness: 0.717081606388092\n",
      "- steps: 0.7149931192398071\n",
      "- simultaneously: 0.7140920758247375\n",
      "- succession: 0.7109583020210266\n",
      "- human: 0.7103732228279114\n",
      "- hearer: 0.7102643251419067\n",
      "- freedom: 0.6969556212425232\n",
      "\n",
      "Most similar words for 'syntax':\n",
      "- quoted: 0.8239123821258545\n",
      "- factor: 0.8120718002319336\n",
      "- evil: 0.8093261122703552\n",
      "- possibly: 0.8073217868804932\n",
      "- convenient: 0.8034989833831787\n",
      "- novel: 0.80058753490448\n",
      "- pitch: 0.7990186810493469\n",
      "- contained: 0.7975811958312988\n",
      "- archaic: 0.7936273217201233\n",
      "- models: 0.7928406596183777\n",
      "\n",
      "Most similar words for 'similar':\n",
      "- unusual: 0.664341151714325\n",
      "- metaphorical: 0.6605664491653442\n",
      "- foregoing: 0.6534263491630554\n",
      "- coupled: 0.6471519470214844\n",
      "- inflectional: 0.6384096741676331\n",
      "- syntactical: 0.6371099948883057\n",
      "- analogical: 0.6337446570396423\n",
      "- numerous: 0.6334929466247559\n",
      "- hie: 0.6330599784851074\n",
      "- differentiation: 0.6326190829277039\n",
      "\n",
      "Most similar words for 'meaning':\n",
      "- signification: 0.7699530720710754\n",
      "- application: 0.5879218578338623\n",
      "- sense: 0.5861349105834961\n",
      "- function: 0.5648723840713501\n",
      "- specialisation: 0.5630260705947876\n",
      "- denotation: 0.5571469664573669\n",
      "- active: 0.5570665597915649\n",
      "- spelling: 0.5566474199295044\n",
      "- creation: 0.5551139712333679\n",
      "- showing: 0.548270583152771\n",
      "\n",
      "Most similar words for 'teutonic':\n",
      "- romance: 0.87779301404953\n",
      "- slavonic: 0.8760868310928345\n",
      "- scandinavian: 0.8381292819976807\n",
      "- declensions: 0.8047911524772644\n",
      "- norman: 0.7805596590042114\n",
      "- european: 0.779539167881012\n",
      "- weak: 0.7681206464767456\n",
      "- ist: 0.7591239809989929\n",
      "- indo: 0.7577603459358215\n",
      "- modern: 0.7466188073158264\n",
      "\n",
      "Most similar words for 'vowels':\n",
      "- equal: 0.861823558807373\n",
      "- genders: 0.8376908302307129\n",
      "- syllables: 0.816977858543396\n",
      "- districts: 0.8164623975753784\n",
      "- copulative: 0.8145084381103516\n",
      "- places: 0.8119536638259888\n",
      "- groupings: 0.8108393549919128\n",
      "- kinds: 0.8048431873321533\n",
      "- events: 0.7967847585678101\n",
      "- senses: 0.7949431538581848\n",
      "\n",
      "Most similar words for 'influence':\n",
      "- exerted: 0.77503502368927\n",
      "- depend: 0.7594651579856873\n",
      "- exercise: 0.7477683424949646\n",
      "- conscious: 0.7240374088287354\n",
      "- civilisation: 0.7234688997268677\n",
      "- mixed: 0.7088728547096252\n",
      "- domain: 0.7086238861083984\n",
      "- synonyms: 0.7067353129386902\n",
      "- adoption: 0.7046388983726501\n",
      "- exert: 0.7016147971153259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in word_list:\n",
    "    similar_words = w2v_model.wv.most_similar(positive=[word], topn=10)\n",
    "    print(f\"Most similar words for '{word}':\")\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"- {similar_word}: {similarity_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "47HiU5gdkdMq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less similar words for 'language':\n",
      "- 3: -0.04215028136968613\n",
      "- b: -0.046031054109334946\n",
      "- cf: -0.05209769681096077\n",
      "- ‘to: -0.06652882695198059\n",
      "- ”: -0.06801827996969223\n",
      "- with: -0.08108284324407578\n",
      "- john: -0.09184236824512482\n",
      "- c: -0.09245195239782333\n",
      "- 5: -0.0965479239821434\n",
      "- e: -0.10087797045707703\n",
      "\n",
      "Less similar words for 'linguistic':\n",
      "- say: -0.014466356486082077\n",
      "- je: -0.037316761910915375\n",
      "- know: -0.0384289026260376\n",
      "- esse: -0.038538914173841476\n",
      "- ‘i: -0.039839088916778564\n",
      "- ‘it: -0.04713747277855873\n",
      "- o: -0.05176649987697601\n",
      "- because: -0.05385943129658699\n",
      "- you: -0.058498725295066833\n",
      "- feminine: -0.06258956342935562\n",
      "\n",
      "Less similar words for 'phenomena':\n",
      "- has: -0.2165675163269043\n",
      "- been: -0.23093591630458832\n",
      "- was: -0.2571670413017273\n",
      "- an: -0.2726992070674896\n",
      "- be: -0.2746957838535309\n",
      "- its: -0.2829643785953522\n",
      "- commonly: -0.28807151317596436\n",
      "- once: -0.2904875576496124\n",
      "- very: -0.29094964265823364\n",
      "- he: -0.2923482060432434\n",
      "\n",
      "Less similar words for 'dialect':\n",
      "- cf: -0.10492998361587524\n",
      "- also: -0.12354466319084167\n",
      "- 1: -0.13488230109214783\n",
      "- into: -0.13510501384735107\n",
      "- may: -0.1358008235692978\n",
      "- take: -0.1401989907026291\n",
      "- our: -0.14162760972976685\n",
      "- amer: -0.1556040644645691\n",
      "- called: -0.15934835374355316\n",
      "- fr: -0.16251763701438904\n",
      "\n",
      "Less similar words for 'imperfect':\n",
      "- has: -0.13778133690357208\n",
      "- had: -0.15373830497264862\n",
      "- his: -0.15546666085720062\n",
      "- they: -0.1562395840883255\n",
      "- after: -0.15714600682258606\n",
      "- would: -0.1600019782781601\n",
      "- he: -0.16010648012161255\n",
      "- to: -0.17694808542728424\n",
      "- have: -0.17883649468421936\n",
      "- e: -0.19352209568023682\n",
      "\n",
      "Less similar words for 'word':\n",
      "- between: -0.017058279365301132\n",
      "- most: -0.06675152480602264\n",
      "- educated: -0.0919782742857933\n",
      "- would: -0.10909570753574371\n",
      "- some: -0.10915746539831161\n",
      "- no: -0.11354615539312363\n",
      "- upon: -0.12044595181941986\n",
      "- all: -0.12364383786916733\n",
      "- many: -0.13673177361488342\n",
      "- not: -0.13708730041980743\n",
      "\n",
      "Less similar words for 'sound':\n",
      "- also: -0.02171393670141697\n",
      "- as: -0.024031827226281166\n",
      "- too: -0.08533833920955658\n",
      "- instances: -0.08682531118392944\n",
      "- our: -0.09390836209058762\n",
      "- like: -0.09423200786113739\n",
      "- american: -0.09795545786619186\n",
      "- singular: -0.10144094377756119\n",
      "- point: -0.1065947562456131\n",
      "- might: -0.10952801257371902\n",
      "\n",
      "Less similar words for 'ideas':\n",
      "- too: -0.06357874721288681\n",
      "- fem: -0.09768151491880417\n",
      "- je: -0.10194821655750275\n",
      "- ne: -0.10364414006471634\n",
      "- esse: -0.10429704934358597\n",
      "- qui: -0.11428898572921753\n",
      "- et: -0.11625585705041885\n",
      "- c’est: -0.11686000227928162\n",
      "- suis: -0.11817438155412674\n",
      "- ‘i: -0.11868199706077576\n",
      "\n",
      "Less similar words for 'mind':\n",
      "- ‘i: -0.05756143853068352\n",
      "- too: -0.08303017914295197\n",
      "- become: -0.10409648716449738\n",
      "- into: -0.1168287917971611\n",
      "- cf: -0.12426356971263885\n",
      "- after: -0.12434182316064835\n",
      "- ‘a: -0.13485483825206757\n",
      "- they: -0.13556547462940216\n",
      "- from: -0.13717111945152283\n",
      "- we: -0.14050371944904327\n",
      "\n",
      "Less similar words for 'syntax':\n",
      "- was: -0.1154446005821228\n",
      "- were: -0.20070824027061462\n",
      "- e: -0.22432053089141846\n",
      "- has: -0.23126250505447388\n",
      "- would: -0.23853103816509247\n",
      "- i: -0.24014142155647278\n",
      "- can: -0.24408461153507233\n",
      "- ‘the: -0.24593718349933624\n",
      "- by: -0.24707089364528656\n",
      "- on: -0.2577751576900482\n",
      "\n",
      "Less similar words for 'similar':\n",
      "- was: -0.02116302028298378\n",
      "- hearer: -0.07148133218288422\n",
      "- has: -0.07692815363407135\n",
      "- part: -0.09089583903551102\n",
      "- participle: -0.09091076254844666\n",
      "- day: -0.09147991240024567\n",
      "- at: -0.0965287983417511\n",
      "- lord: -0.10413272678852081\n",
      "- plur: -0.11044500768184662\n",
      "- self: -0.12286695837974548\n",
      "\n",
      "Less similar words for 'meaning':\n",
      "- on: -0.052020683884620667\n",
      "- educated: -0.0591108575463295\n",
      "- ii: -0.07642519474029541\n",
      "- my: -0.07981067895889282\n",
      "- i: -0.08049017190933228\n",
      "- 1: -0.09333819150924683\n",
      "- best: -0.10166549682617188\n",
      "- as: -0.10232261568307877\n",
      "- non: -0.10405426472425461\n",
      "- p: -0.10611999779939651\n",
      "\n",
      "Less similar words for 'teutonic':\n",
      "- subject: -0.09173087030649185\n",
      "- sentence: -0.09251086413860321\n",
      "- if: -0.09787896275520325\n",
      "- line: -0.10878711938858032\n",
      "- read: -0.10938097536563873\n",
      "- can: -0.11496290564537048\n",
      "- going: -0.1293341964483261\n",
      "- make: -0.13533541560173035\n",
      "- not: -0.14332012832164764\n",
      "- john: -0.14436213672161102\n",
      "\n",
      "Less similar words for 'vowels':\n",
      "- eng: -0.12092816829681396\n",
      "- ‘to: -0.12997378408908844\n",
      "- into: -0.14339284598827362\n",
      "- amer: -0.14396564662456512\n",
      "- by: -0.16900727152824402\n",
      "- one’s: -0.16982662677764893\n",
      "- his: -0.17532941699028015\n",
      "- from: -0.1772511750459671\n",
      "- cf: -0.1814567744731903\n",
      "- ‘a: -0.18232424557209015\n",
      "\n",
      "Less similar words for 'influence':\n",
      "- used: -0.07311467826366425\n",
      "- o: -0.07722366601228714\n",
      "- b: -0.08462005108594894\n",
      "- esse: -0.09988714754581451\n",
      "- h: -0.1120973527431488\n",
      "- e: -0.11594545096158981\n",
      "- il: -0.11771596968173981\n",
      "- fr: -0.1218123659491539\n",
      "- lat: -0.12283679097890854\n",
      "- good: -0.12508469820022583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in word_list:\n",
    "    similar_words = w2v_model.wv.most_similar(negative=[word], topn=10)\n",
    "    print(f\"Less similar words for '{word}':\")\n",
    "    for similar_word, similarity_score in similar_words:\n",
    "        print(f\"- {similar_word}: {similarity_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando en cuenta que el libro trata sobre lingüística, se seleccionaron palabras relevantes que se relacionen con el tema. Por ejemplo, la palabra \"language\" tiene similitud con \"dialect\", \"orthography\", \"alphabet\", \"standard\", \"type\", \"pre\", \"harmony\", \"usage\", \"adoption\" e \"idiom\". En este caso, tiene sentido la mayoría de las palabras, pero \"pre\" podría estar relacionado en este contexto. Algo interesante es que al analizar la palabra \"dialect\", no se encuentra la palabra \"language\" previamente analizada. En su lugar, se observa que tiene similitudes con otras palabras que se interpretarían más en el contexto. Otra palabra interesante en su análisis fue \"teutonic\", cuyas palabras similares son \"romance\", \"slavonic\", \"scandinavian\", \"declensions\", \"norman\", \"european\", \"weak\", \"ist\", \"indo\" y \"modern\". Las primeras se relacionan porque en este contexto puede significar orígenes lingüísticos. Si hablamos de declinaciones, justamente se sabe que es parte importante de un lenguaje y deberia estar relacionado.\n",
    "La mayoría de las palabras que presentan poca similitud con las palabras escogidas son en general adverbios, adverbios, artículos y palabras muy generales, o letras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g8UVWe6lFmh"
   },
   "source": [
    "### Graficos de agrupación de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "pDxEVXAivjr9"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    \n",
    "from sklearn.manifold import TSNE                   \n",
    "import numpy as np                                  \n",
    "\n",
    "def reduce_dimensions(model, num_dimensions = 2 ):\n",
    "     \n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  \n",
    "\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    return vectors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "NCCXtDpcugmd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.32.0.min.js\"></script>                <div id=\"1d15db27-e199-46d8-81de-7a59e3fbfbd9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d15db27-e199-46d8-81de-7a59e3fbfbd9\")) {                    Plotly.newPlot(                        \"1d15db27-e199-46d8-81de-7a59e3fbfbd9\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"the\",\"of\",\"in\",\"to\",\"and\",\"a\",\"as\",\"is\",\"we\",\"that\",\"it\",\"which\",\"\\u2019\",\"or\",\"be\",\"by\",\"are\",\"with\",\"this\",\"such\",\"for\",\"have\",\"from\",\"language\",\"but\",\"not\",\"i\",\"may\",\"word\",\"words\",\"one\",\"an\",\"has\",\"other\",\"its\",\"case\",\"was\",\"on\",\"these\",\"more\",\"at\",\"etc\",\"same\",\"he\",\"must\",\"english\",\"when\",\"thus\",\"meaning\",\"form\",\"all\",\"no\",\"e\",\"cases\",\"their\",\"so\",\"two\",\"into\",\"they\",\"our\",\"like\",\"some\",\"if\",\"been\",\"any\",\"will\",\"again\",\"there\",\"between\",\"sound\",\"where\",\"verb\",\"only\",\"subject\",\"instance\",\"find\",\"would\",\"used\",\"can\",\"sentence\",\"forms\",\"even\",\"then\",\"than\",\"different\",\"very\",\"his\",\"use\",\"who\",\"french\",\"fact\",\"first\",\"\\u2018the\",\"however\",\"were\",\"common\",\"predicate\",\"latin\",\"languages\",\"those\",\"what\",\"now\",\"change\",\"g\",\"cf\",\"many\",\"present\",\"most\",\"had\",\"though\",\"s\",\"also\",\"upon\",\"another\",\"noun\",\"german\",\"should\",\"become\",\"them\",\"say\",\"sense\",\"each\",\"time\",\"sounds\",\"you\",\"group\",\"us\",\"ii\",\"adjective\",\"certain\",\"man\",\"\\u2018a\",\"new\",\"both\",\"similar\",\"well\",\"speaker\",\"still\",\"do\",\"development\",\"\\u2018to\",\"way\",\"once\",\"sentences\",\"part\",\"much\",\"him\",\"place\",\"without\",\"groups\",\"instances\",\"plural\",\"compound\",\"standard\",\"hand\",\"might\",\"sometimes\",\"after\",\"course\",\"indeed\",\"called\",\"individual\",\"always\",\"usage\",\"less\",\"verbs\",\"good\",\"past\",\"genitive\",\"object\",\"itself\",\"often\",\"accusative\",\"being\",\"before\",\"grammatical\",\"here\",\"commonly\",\"found\",\"yet\",\"analogy\",\"construction\",\"iii\",\"old\",\"eng\",\"b\",\"come\",\"expression\",\"similarly\",\"further\",\"singular\",\"linguistic\",\"while\",\"me\",\"influence\",\"substantive\",\"own\",\"original\",\"nouns\",\"speak\"],\"x\":[-14.367156028747559,-21.89588165283203,8.327274322509766,-0.6337550282478333,-4.654689311981201,-9.707807540893555,6.629991054534912,-16.877605438232422,10.00692367553711,-10.55635929107666,4.910290241241455,-32.59780502319336,29.482439041137695,-11.215448379516602,7.047411918640137,-5.385307788848877,-9.33350944519043,-10.624129295349121,0.1009788066148758,-32.988685607910156,3.8144872188568115,-3.7918620109558105,-10.17948055267334,-15.957610130310059,-8.337929725646973,2.342160224914551,34.837242126464844,13.496323585510254,-7.8855881690979,-12.148051261901855,-13.09260082244873,-7.516810417175293,-3.3768954277038574,-17.67957305908203,-22.859222412109375,-8.67939567565918,1.434293270111084,12.30179500579834,-15.299173355102539,-10.730860710144043,8.410574913024902,25.883163452148438,-34.365455627441406,29.918474197387695,5.857081413269043,4.15689754486084,7.349293231964111,1.7897405624389648,-25.097457885742188,-11.89881420135498,-19.06256866455078,-12.651229858398438,24.4062557220459,-11.00395679473877,-28.96949005126953,-7.7650980949401855,-20.461271286010742,7.839855194091797,17.588071823120117,-18.19447135925293,9.399898529052734,-19.222043991088867,19.64658546447754,-4.8429718017578125,-27.254629135131836,14.716446876525879,12.194544792175293,-5.8434553146362305,-25.482807159423828,-37.84967803955078,1.6119548082351685,-0.6171424388885498,-17.87204933166504,-21.245283126831055,-0.933118462562561,4.305241107940674,4.905918598175049,-2.1541748046875,14.475547790527344,-37.29736328125,-19.96974754333496,-15.410860061645508,1.488869547843933,-25.5455265045166,-24.871347427368164,-3.134211301803589,35.15133285522461,-3.3784632682800293,27.20765495300293,42.71350860595703,2.6978557109832764,1.019902229309082,39.80559539794922,7.798492431640625,-8.673346519470215,-14.04039192199707,-21.716060638427734,9.769001960754395,-23.31473159790039,2.1388959884643555,11.83269214630127,2.0652613639831543,-28.04194450378418,18.54755401611328,30.992504119873047,-11.533432960510254,5.14957332611084,-27.353313446044922,-3.4670169353485107,-7.518797874450684,22.045719146728516,2.6006438732147217,13.107370376586914,-7.471621036529541,-1.9643908739089966,12.128327369689941,14.160795211791992,31.869579315185547,-3.9007303714752197,16.500221252441406,-7.346358299255371,-31.744871139526367,10.360034942626953,-21.9384822845459,30.242656707763672,-30.672510147094727,8.772852897644043,37.83449172973633,-1.709855556488037,-25.905277252197266,24.743356704711914,27.571622848510742,-29.832733154296875,-17.071048736572266,-33.857757568359375,25.102893829345703,-13.805425643920898,6.4540534019470215,13.192849159240723,-27.06575584411621,28.628904342651367,-9.462453842163086,6.679340839385986,-7.000554084777832,-17.555505752563477,-7.57037878036499,30.707853317260742,8.1212158203125,-5.091811180114746,-28.30278778076172,-13.711038589477539,3.117920398712158,-9.579316139221191,-23.51378631591797,11.72291374206543,13.289494514465332,0.36293792724609375,11.127367973327637,-6.651541709899902,2.4964499473571777,9.239507675170898,-19.2896728515625,7.703158855438232,-20.0728759765625,-10.579779624938965,-11.989581108093262,25.772497177124023,4.112346649169922,1.9535088539123535,-22.40186309814453,-4.593890190124512,0.6830320358276367,1.166056513786316,-20.293264389038086,12.006650924682617,-30.241844177246094,9.435415267944336,-8.438835144042969,4.70281457901001,-6.412673473358154,-17.344440460205078,-5.4729485511779785,37.61848068237305,12.221423149108887,34.77653121948242,21.560894012451172,9.274154663085938,-12.35954761505127,9.887585639953613,-7.776821136474609,4.718624591827393,-33.11655807495117,-14.919936180114746,35.74117660522461,-17.727453231811523,-2.1355228424072266,-34.633792877197266,-21.85470962524414,-12.044364929199219,15.867377281188965],\"xaxis\":\"x\",\"y\":[1.1469944715499878,1.9922605752944946,10.237156867980957,-17.539213180541992,19.77128791809082,1.9587674140930176,5.3480730056762695,-18.097429275512695,-13.09863567352295,-7.007213592529297,-5.209237098693848,-10.6502685546875,5.853094100952148,3.1581952571868896,-17.885705947875977,-18.614501953125,16.318748474121094,26.170923233032227,-5.611518383026123,-13.867744445800781,1.9962356090545654,29.169679641723633,14.60063648223877,3.553091526031494,6.749244213104248,-16.710311889648438,19.921173095703125,-15.518143653869629,2.436833143234253,15.588274002075195,-6.8592963218688965,1.453071117401123,29.678285598754883,17.668895721435547,-9.6463041305542,8.287715911865234,19.829408645629883,25.94721221923828,18.70448112487793,-22.075674057006836,-0.3072468936443329,10.26255989074707,-5.337862491607666,-5.376852989196777,-10.428081512451172,9.111139297485352,1.1340069770812988,6.014672756195068,-8.330184936523438,6.158899784088135,18.2095947265625,-23.074661254882812,19.59415054321289,10.02480411529541,-14.51651668548584,-24.33062171936035,19.794340133666992,25.460966110229492,-18.336509704589844,30.46896743774414,7.8880791664123535,17.394580841064453,-21.425243377685547,-28.782489776611328,-5.645363807678223,-14.947279930114746,8.738096237182617,22.619462966918945,10.442965507507324,0.06820376217365265,17.261503219604492,10.5452880859375,-21.21534538269043,-22.254783630371094,19.45226287841797,13.669443130493164,-20.0137996673584,5.939571857452393,-15.473366737365723,-4.910552024841309,15.024164199829102,-28.106111526489258,-5.574848175048828,-13.031122207641602,16.06198501586914,21.57943344116211,-4.786229610443115,24.383344650268555,-3.9242055416107178,7.49518346786499,-5.638465404510498,23.374553680419922,7.501404762268066,-7.185862064361572,15.60275650024414,-12.516831398010254,-21.830318450927734,16.067190170288086,18.427785873413086,27.609445571899414,-6.190860748291016,4.030431747436523,-4.667555809020996,17.86707878112793,17.161283493041992,18.197071075439453,21.14598274230957,19.322710037231445,29.470199584960938,7.506952285766602,18.191686630249023,-0.818449854850769,26.053585052490234,-1.7793015241622925,11.898136138916016,15.293278694152832,-14.229887962341309,-12.623790740966797,-13.77319622039795,-8.334205627441406,2.174973964691162,3.0115888118743896,-0.747958242893219,12.596049308776855,-7.393848419189453,-0.9124929904937744,-20.833908081054688,18.32354736328125,10.37801742553711,-6.493395805358887,5.604691028594971,6.354393005371094,2.3450989723205566,21.35171127319336,-13.219738006591797,-15.538671493530273,-18.3708438873291,-5.502305030822754,-12.673945426940918,0.4573059678077698,2.1895487308502197,6.978484630584717,-5.946767330169678,19.719881057739258,25.917951583862305,-22.65978240966797,-11.269196510314941,-1.505379557609558,12.845216751098633,12.084188461303711,22.571292877197266,16.217086791992188,3.7588205337524414,-13.144716262817383,26.010738372802734,-15.470072746276855,8.431966781616211,10.11815071105957,8.083992958068848,-4.324278354644775,16.616716384887695,16.835039138793945,-11.390759468078613,-4.414702415466309,-22.350177764892578,20.335012435913086,1.9801005125045776,20.855506896972656,15.67569351196289,-22.072757720947266,-20.360502243041992,4.1050028800964355,14.148804664611816,-17.011220932006836,0.5039641261100769,10.114611625671387,-2.6726722717285156,-29.042945861816406,7.340856552124023,-14.854674339294434,1.5989910364151,5.447274684906006,17.90021324157715,17.19576644897461,-1.780092477798462,19.852373123168945,-11.81879997253418,-3.9053244590759277,13.889357566833496,-15.927474975585938,17.15679931640625,0.28182870149612427,-7.810916900634766,5.991496562957764,2.286022186279297,11.238865852355957,3.8506288528442383,-9.156980514526367,20.48573112487793,-9.44514274597168],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1d15db27-e199-46d8-81de-7a59e3fbfbd9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los embedddings en 2D\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "vecs, labels = reduce_dimensions(w2v_model)\n",
    "\n",
    "MAX_WORDS=200\n",
    "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
    "fig.show(renderer=\"colab\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.32.0.min.js\"></script>                <div id=\"7d9c62be-1567-41ed-8877-5cc7d2ab04b8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7d9c62be-1567-41ed-8877-5cc7d2ab04b8\")) {                    Plotly.newPlot(                        \"7d9c62be-1567-41ed-8877-5cc7d2ab04b8\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":2},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"the\",\"of\",\"in\",\"to\",\"and\",\"a\",\"as\",\"is\",\"we\",\"that\",\"it\",\"which\",\"\\u2019\",\"or\",\"be\",\"by\",\"are\",\"with\",\"this\",\"such\",\"for\",\"have\",\"from\",\"language\",\"but\",\"not\",\"i\",\"may\",\"word\",\"words\",\"one\",\"an\",\"has\",\"other\",\"its\",\"case\",\"was\",\"on\",\"these\",\"more\",\"at\",\"etc\",\"same\",\"he\",\"must\",\"english\",\"when\",\"thus\",\"meaning\",\"form\",\"all\",\"no\",\"e\",\"cases\",\"their\",\"so\",\"two\",\"into\",\"they\",\"our\",\"like\",\"some\",\"if\",\"been\",\"any\",\"will\",\"again\",\"there\",\"between\",\"sound\",\"where\",\"verb\",\"only\",\"subject\",\"instance\",\"find\",\"would\",\"used\",\"can\",\"sentence\",\"forms\",\"even\",\"then\",\"than\",\"different\",\"very\",\"his\",\"use\",\"who\",\"french\",\"fact\",\"first\",\"\\u2018the\",\"however\",\"were\",\"common\",\"predicate\",\"latin\",\"languages\",\"those\",\"what\",\"now\",\"change\",\"g\",\"cf\",\"many\",\"present\",\"most\",\"had\",\"though\",\"s\",\"also\",\"upon\",\"another\",\"noun\",\"german\",\"should\",\"become\",\"them\",\"say\",\"sense\",\"each\",\"time\",\"sounds\",\"you\",\"group\",\"us\",\"ii\",\"adjective\",\"certain\",\"man\",\"\\u2018a\",\"new\",\"both\",\"similar\",\"well\",\"speaker\",\"still\",\"do\",\"development\",\"\\u2018to\",\"way\",\"once\",\"sentences\",\"part\",\"much\",\"him\",\"place\",\"without\",\"groups\",\"instances\",\"plural\",\"compound\",\"standard\",\"hand\",\"might\",\"sometimes\",\"after\",\"course\",\"indeed\",\"called\",\"individual\",\"always\",\"usage\",\"less\",\"verbs\",\"good\",\"past\",\"genitive\",\"object\",\"itself\",\"often\",\"accusative\",\"being\",\"before\",\"grammatical\",\"here\",\"commonly\",\"found\",\"yet\",\"analogy\",\"construction\",\"iii\",\"old\",\"eng\",\"b\",\"come\",\"expression\",\"similarly\",\"further\",\"singular\",\"linguistic\",\"while\",\"me\",\"influence\",\"substantive\",\"own\",\"original\",\"nouns\",\"speak\"],\"x\":[-17.33863639831543,-28.585145950317383,3.9453136920928955,-7.1304731369018555,4.996036052703857,-18.579500198364258,5.375592231750488,-11.862227439880371,4.299571990966797,-8.645520210266113,3.8769752979278564,-34.83234786987305,31.453542709350586,-16.573898315429688,-1.4646612405776978,-14.499236106872559,-3.9064769744873047,-16.87655258178711,-4.447545051574707,-10.4327974319458,5.796926498413086,-0.07874246686697006,-4.48498010635376,-13.019174575805664,-7.405381202697754,6.692633152008057,39.568363189697266,5.568979263305664,-7.051375389099121,-10.148981094360352,-12.058809280395508,-9.969594955444336,-1.4400221109390259,-16.489835739135742,-24.996326446533203,-2.0561892986297607,5.08230447769165,11.743514060974121,-18.073564529418945,-0.6435068845748901,4.112215042114258,26.29210090637207,-32.799598693847656,32.19667434692383,2.943127155303955,0.6095949411392212,7.20044469833374,2.7880070209503174,-34.3977165222168,-22.598278045654297,-19.859525680541992,-6.008963584899902,30.185325622558594,-4.754689693450928,-21.493310928344727,2.8535306453704834,-24.764822006225586,17.65787696838379,13.500736236572266,1.5754824876785278,6.686614513397217,-19.051103591918945,4.380893707275391,-10.380072593688965,-35.65399932861328,3.4421188831329346,1.2312501668930054,-4.235709190368652,-28.544137954711914,-43.309932708740234,9.041132926940918,-13.56425666809082,-16.381494522094727,-22.060426712036133,-1.0609028339385986,0.9660199284553528,4.156408309936523,-3.943718671798706,3.1339542865753174,-39.81965637207031,-18.106550216674805,-0.02263224497437477,0.1752510666847229,-20.042104721069336,-23.393037796020508,0.40317249298095703,32.118743896484375,-6.026767730712891,21.597076416015625,29.932584762573242,-5.63544225692749,-11.58444595336914,30.414691925048828,7.418598651885986,-4.924892902374268,-12.293048858642578,-22.99944496154785,19.432823181152344,-18.100940704345703,8.373455047607422,3.3199329376220703,3.232016086578369,-37.55729293823242,23.37668228149414,39.25369644165039,-10.390796661376953,-3.903031826019287,-29.73493194580078,-1.5097585916519165,-3.490966320037842,27.86510467529297,8.064665794372559,12.940176010131836,-9.831403732299805,-17.452220916748047,14.77653980255127,5.762864112854004,21.253042221069336,-9.142900466918945,15.066808700561523,-5.53608512878418,-27.361238479614258,8.950385093688965,-20.660493850708008,33.916988372802734,-37.236812591552734,6.966171741485596,47.42055130004883,-17.697179794311523,-31.885177612304688,24.40093994140625,23.00504493713379,-37.30061340332031,-20.509227752685547,-15.25951862335205,21.646757125854492,-9.317096710205078,4.250492095947266,6.678565979003906,-34.77625274658203,24.94206428527832,-6.307529926300049,5.227297306060791,0.19883789122104645,9.64049243927002,7.103093147277832,21.871845245361328,2.2146835327148438,-30.166099548339844,-29.593997955322266,-8.147292137145996,7.833281517028809,-14.903038024902344,-14.02436637878418,10.537845611572266,7.172361373901367,-0.26453107595443726,7.202681541442871,-5.938416004180908,2.714033842086792,17.014232635498047,-16.560020446777344,9.016522407531738,-20.956218719482422,-1.5641576051712036,-12.21645736694336,23.804080963134766,-0.4948674440383911,9.796418190002441,-23.904531478881836,-14.7598295211792,2.605569839477539,11.351110458374023,-26.400487899780273,12.739021301269531,-32.00442123413086,10.646113395690918,1.9086965322494507,3.7051239013671875,-8.691241264343262,-13.20736312866211,-6.421528339385986,48.5234489440918,14.086816787719727,25.849645614624023,23.375349044799805,7.281648635864258,-29.7081241607666,10.032658576965332,-4.813482284545898,12.617074966430664,-30.90397834777832,-16.03841209411621,32.89655685424805,-11.597491264343262,-18.629356384277344,-22.232938766479492,-28.741975784301758,-12.750568389892578,10.892163276672363],\"y\":[0.17666615545749664,-3.923962354660034,-20.19559669494629,9.309308052062988,-22.36901092529297,-7.773989677429199,-2.0775680541992188,7.160892009735107,19.64228057861328,10.418936729431152,4.315800666809082,2.134037733078003,-14.557573318481445,-8.47580337524414,21.60671615600586,11.907286643981934,-28.337636947631836,-24.19266700744629,28.063030242919922,-26.398008346557617,-8.320685386657715,-10.8302001953125,-35.11155700683594,14.486123085021973,-7.89757776260376,19.902128219604492,12.116731643676758,11.157085418701172,-18.65242576599121,-22.363454818725586,-9.230855941772461,-16.923612594604492,-14.018109321594238,-6.367920398712158,5.009422779083252,-10.868781089782715,-5.315871715545654,-8.455670356750488,-23.0833740234375,10.989665985107422,22.1369686126709,-1.592067003250122,-13.789429664611816,11.250934600830078,-1.2504531145095825,-20.506013870239258,-6.550863742828369,-29.12611961364746,12.751574516296387,-4.2540602684021,-2.5822956562042236,5.476407527923584,-14.997262954711914,-16.913297653198242,22.203933715820312,6.096502304077148,-27.436979293823242,-13.21964168548584,5.798213958740234,28.52886390686035,-15.408963203430176,-5.493456840515137,-4.9950761795043945,1.2196385860443115,10.036791801452637,14.476810455322266,-15.172554016113281,1.080628752708435,-14.333017349243164,7.730125904083252,-27.233150482177734,-15.17837905883789,-31.39514923095703,-5.059206485748291,15.99114990234375,-28.025880813598633,4.4766526222229,-22.47898292541504,9.918890953063965,-13.94363021850586,-20.279401779174805,-10.552058219909668,31.224042892456055,26.213481903076172,-24.708084106445312,-0.990172266960144,4.312209129333496,-29.734447479248047,4.734060287475586,-20.53833770751953,32.36393356323242,9.296342849731445,-10.782224655151367,-1.719659686088562,-29.353025436401367,-2.905721426010132,-1.9202055931091309,-22.973783493041992,-19.54158592224121,-8.32988166809082,21.762922286987305,-12.777812957763672,5.1577019691467285,-17.817903518676758,-4.124741077423096,-30.145004272460938,38.32509994506836,1.717366337776184,-10.756124496459961,-9.69770336151123,-19.5555477142334,-3.3894901275634766,-7.013412952423096,0.4334595799446106,-11.989119529724121,-24.567920684814453,12.886467933654785,7.1366658210754395,0.9791748523712158,21.24028778076172,-14.949932098388672,6.158318519592285,20.454496383666992,-13.95948314666748,15.559945106506348,4.9950175285339355,26.145702362060547,5.02003288269043,-17.959348678588867,14.474237442016602,4.840616703033447,-11.163976669311523,-5.373202323913574,-28.369916915893555,-25.035682678222656,24.891237258911133,23.112869262695312,-12.106158256530762,18.389415740966797,-1.965696930885315,-1.656578779220581,-15.773274421691895,-8.183606147766113,-26.17020034790039,-2.233139991760254,4.4421772956848145,9.897283554077148,25.841899871826172,-12.448884963989258,-15.523031234741211,-24.018890380859375,-19.882976531982422,-12.538496971130371,0.4037920832633972,-9.735333442687988,9.230280876159668,-22.51380157470703,-18.16334342956543,-5.9806928634643555,-1.7347201108932495,-26.046937942504883,-1.6358181238174438,9.19542407989502,-0.9815959930419922,9.054457664489746,-29.738529205322266,11.500853538513184,38.839149475097656,-24.73149871826172,-1.7228705883026123,8.395195007324219,-16.582748413085938,-25.868762969970703,8.311988830566406,-13.484164237976074,-17.257930755615234,12.596445083618164,-20.622468948364258,-21.32427978515625,3.2089953422546387,10.740396499633789,-15.564434051513672,2.646817684173584,-30.237035751342773,-5.7706780433654785,-23.247236251831055,14.338189125061035,21.47270965576172,-21.5639705657959,24.12384796142578,-19.794710159301758,13.527902603149414,10.66856575012207,5.509405612945557,16.551748275756836,-9.882024765014648,10.055523872375488,5.868438243865967,-32.2324333190918,19.762405395507812],\"z\":[-3.670297622680664,-5.265122890472412,-10.99612045288086,9.342488288879395,-17.276594161987305,7.269665241241455,-14.585742950439453,9.632491111755371,26.500614166259766,1.053186297416687,6.971017837524414,18.155139923095703,4.2218146324157715,1.6684967279434204,23.482807159423828,18.86742401123047,-7.145616054534912,13.400744438171387,-0.11276814341545105,5.529708385467529,-10.659566879272461,26.12163543701172,-3.9150493144989014,-10.39439868927002,-5.627371788024902,20.53302001953125,1.9937129020690918,32.85300064086914,14.803740501403809,-12.287837982177734,7.043769359588623,17.06739616394043,24.0610408782959,-30.22756576538086,8.974631309509277,-12.311568260192871,33.70711898803711,-24.587928771972656,-7.366672039031982,-23.887981414794922,-16.134441375732422,-10.87731647491455,-6.127131462097168,11.027008056640625,23.20140838623047,-4.272950649261475,12.108848571777344,-9.610396385192871,8.183523178100586,8.295989036560059,-29.534854888916016,-28.442258834838867,-17.5450439453125,-17.701757431030273,-1.8764418363571167,-21.034099578857422,-5.25736141204834,9.911410331726074,20.46359634399414,-20.406444549560547,-25.217206954956055,-26.458555221557617,-21.60978126525879,25.460914611816406,1.5958912372589111,30.96140480041504,-14.999807357788086,-12.553112030029297,-12.503767967224121,2.526400566101074,2.012204885482788,22.012109756469727,8.814798355102539,25.398122787475586,-10.644007682800293,-3.1285736560821533,30.792238235473633,12.197649955749512,29.607362747192383,-2.035551071166992,-16.274873733520508,-5.7720208168029785,-1.6582385301589966,-8.990281105041504,-10.111696243286133,-20.829389572143555,15.781461715698242,11.361936569213867,16.327058792114258,-1.4351894855499268,-5.0378875732421875,32.49319839477539,2.550300359725952,20.009550094604492,-3.4059841632843018,4.0945963859558105,26.090606689453125,-1.3008161783218384,-23.13092803955078,-6.626485347747803,-5.54630708694458,11.95224666595459,4.233753204345703,-17.36395263671875,5.837144374847412,-11.60765266418457,1.5021967887878418,-19.782730102539062,22.731428146362305,-8.368701934814453,-10.555520057678223,1.1834074258804321,-27.7650146484375,-13.434725761413574,22.480499267578125,-10.038166046142578,28.25967025756836,23.605192184448242,-31.22336196899414,5.603702068328857,16.728120803833008,-24.81797981262207,-17.865375518798828,-22.48954963684082,9.978639602661133,-11.84530258178711,16.727294921875,4.362504005432129,17.745838165283203,1.9160735607147217,-12.8069429397583,2.2818009853363037,-1.425887942314148,1.745849370956421,3.5220272541046143,-7.674610614776611,-23.487686157226562,17.84807586669922,16.65707778930664,5.484035968780518,4.8177337646484375,-7.711106777191162,18.400800704956055,-15.323993682861328,-31.15185546875,-21.969669342041016,17.25189781188965,-13.345122337341309,15.08620548248291,-19.426939010620117,-18.639225006103516,4.70543098449707,7.173972129821777,6.862040042877197,-22.423049926757812,31.872549057006836,3.308523654937744,-14.847872734069824,-14.084113121032715,15.6837797164917,-0.6757258772850037,-27.042924880981445,23.5070858001709,5.715799331665039,-24.601852416992188,-4.440688610076904,-14.962767601013184,6.539366722106934,6.217814922332764,22.568880081176758,24.179309844970703,6.844380855560303,9.462714195251465,20.96329689025879,15.418793678283691,7.264467716217041,-14.321908950805664,15.97399616241455,0.7452268600463867,11.584473609924316,-22.97311019897461,5.820542335510254,2.025846004486084,-4.1394829750061035,22.240638732910156,-8.658284187316895,17.141427993774414,1.9457027912139893,-3.706712007522583,-2.0348055362701416,6.080674648284912,-16.407724380493164,14.278491020202637,10.211931228637695,-22.170642852783203,20.198278427124023,-22.880821228027344,12.13889217376709,-4.5279130935668945,4.622216701507568],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7d9c62be-1567-41ed-8877-5cc7d2ab04b8');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los embedddings en 3D\n",
    "vecs, labels = reduce_dimensions(w2v_model,3)\n",
    "\n",
    "fig = px.scatter_3d(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], z=vecs[:MAX_WORDS,2],text=labels[:MAX_WORDS])\n",
    "fig.update_traces(marker_size = 2)\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar los graficos, se pueden encontrar cosas interesantes, por ejemplo, \"accusative\" y \"genitive\" son palabras que se encuentran cerca en el grafico. se debe tomar en cuenta que los dos son casos gramaticales presentes en varios idiomas. Otra cosa es que los advervios de tiempo como \"sometimes\" y \"often\" se encuentran cerca. Ciertos lenguajes Palabras como \"substantive\", \"subject\", \"noun\", \"object\", \"predicate\" se encuentran cerca dado que son partes esenciales de un lenguaje por lo que esto tendria sentido dentro de este contexto."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
